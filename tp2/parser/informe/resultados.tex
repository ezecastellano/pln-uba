\section{Procesamiento de textos en Inglés}

\subsection{Tagging y Chunking sobre los textos originales}

Para poder realizar este proceso creamos utilizamos el Transformador que realizamos en java para quedarnos con las tres versiones (chunked, postagged, tokenized) de los archivos en el formato de OpenNLP. 

Para que la herramienta pueda realizar el proceso, descargamos modelos ya entrenados para el inglés del sitio web de OpenNLP (http://opennlp.sourceforge.net/models-1.5/). 

Luego postaggeamos el tokenizado con la herramienta. Decidimos realizar las pruebas con el modelo basado en maxent y el de perceptron para ver las diferencias en los resultados. Para ejectuar la herramienta utilizamos el siguiente comando:

\texttt{opennlp POSTagger en-pos-maxent.bin < tokenized > postagged}

\texttt{opennlp POSTagger en-pos-perceptron.bin < tokenized > postagged}

Hicimos lo mismo con la versión postaggeada del original para obtener la versión chunkeada por opennlp:

\texttt{opennlp ChunkerME en-chunker.bin < tokenized > postaggged}

\subsection{Postagging Accuracy y las cinco dimensiones de error más frecuentes}
	
Para calcular esto primero convertimos los archivos de postagging en formato 
OpenNLP a formato BIO y luego utilizamos el programa para comparar postagged
que nos permitía obtener la métrica necesaria y las dimensiones de error más 
frecuentes.

Decidimos que no importaba el en que archivo se produciera la diferencia de 
etiqueta con el otro, es decir no importaba el orden. Por ejemplo que los errores 
NP NNP eran equivalentes a los NNP NP a la hora de sacar la estadística. 

\subsubsection{Maxent}

\begin{itemize}

		\item Genia
		
		Posttaging Accuracy: 0.866182504333326

		\begin{center}
			\begin{tabular}{| c | c | c |}\hline
			Etiqueta & Cantidad & Incidencia\\\hline
			NN NNP   & 2661     & 0.43630103295622236\\
			JJ NN    & 1136     & 0.18626004262993934\\
			JJ VBN   & 197      & 0.0323003771110018\\
			NN CD    & 143      & 0.023446466633874407\\
			NNS VBZ  & 137      & 0.022462698803082472\\\hline
			Subtotal & 4274     & 0.7007706181341203\\\hline
			\end{tabular}
		\end{center}

		\item WsjSubset

		Posttaging Accuracy: 0.9715262680203475
		
		\begin{center}
			\begin{tabular}{| c | c | c |}\hline
			Etiqueta & Cantidad & Incidencia\\\hline
			JJ NN    & 187      & 0.13862120088954782\\
			VBN VBD  & 129      & 0.09562638991845812\\
			IN RP    & 95       & 0.07042253521126761\\
			RB IN    & 87       & 0.06449221645663454\\
			NNP NNPS & 77       & 0.05707931801334322\\\hline
			Subtotal & 575      & 0.4262416604892513\\\hline
			\end{tabular}
		\end{center}
\end{itemize}


\subsubsection{Perceptron}

\begin{itemize}

		\item Genia
		
		Posttaging Accuracy: 0.8222568400728437
		\begin{center}
			\begin{tabular}{| c | c | c |}\hline
			Etiqueta & Cantidad & Incidencia\\\hline
			NN NNP 		& 2337 	& 0.288482903345266\\
			NN `` 		& 1831 	& 0.2260214788297741\\
			JJ NN 		& 815 	& 0.10060486359708679\\
			JJ `` 		& 489 	& 0.060362918158252066\\
			NN O 		& 297 	& 0.03666214047648438\\\hline
			Subtotal	& 5769 	& 0.7121343044068633\\\hline
			\end{tabular}
		\end{center}

		
		\item WsjSubset
		
		Posttaging Accuracy: 0.965299617958081
		
		\begin{center}
			\begin{tabular}{| c | c | c |}\hline
			Etiqueta & Cantidad & Incidencia\\\hline
			JJ NN 		& 173 	& 0.10523114355231143\\
			VBN VBD 	& 134 	& 0.08150851581508516\\
			IN RP 		& 106 	& 0.06447688564476886\\
			NNP NNPS 	& 79 	& 0.04805352798053528\\
			IN RB 		& 77 	& 0.04683698296836983\\\hline
			Subtotal 	& 569 	& 0.34610705596107055\\\hline
			\end{tabular}
		\end{center}
\end{itemize}

\subsection{Chunking Precision y Recall para chunks verbales y nominales}

Para calcular estas dos métricas primero pasamos el archivo de chunking generado 
por OpenNLP al formato de BIO y luego utilizando un script hecho en java tomamos 
el archivo original y el procesado por opennlp para generar un archivo que en las 
tres primeras columnas tenía la información original y en la última la obtenida del 
procesamiento para luego poder utilizar el script conlleval.pl .

\subsubsection{Genia}

\texttt{./conlleval.pl -l < original/gen/genia.compare}

\begin{center}
	\begin{tabular}{| c | c | c | c |}
		\hline
			& Precision &  Recall  & F-Measure \\\hline
		ADJP    &   80.54\% &  70.92\% &  75.42 \\
		ADVP    &   74.36\% &  78.52\% &  76.38 \\
		CC      &    0.00\% &   0.00\% &   0.00 \\
		CD      &    0.00\% &   0.00\% &   0.00 \\
		CONJP   &  100.00\% &  18.03\% &  30.56 \\
		DT      &    0.00\% &   0.00\% &   0.00 \\
		FW      &    0.00\% &   0.00\% &   0.00 \\
		IN      &    0.00\% &   0.00\% &   0.00 \\
		JJ      &    0.00\% &   0.00\% &   0.00 \\
		JJ|RB   &    0.00\% &   0.00\% &   0.00 \\
		LS      &    0.00\% &   0.00\% &   0.00 \\
		LST     &    0.00\% &   0.00\% &   0.00 \\
		NN      &    0.00\% &   0.00\% &   0.00 \\
		NNS     &    0.00\% &   0.00\% &   0.00 \\
		NP      &   86.60\% &  82.57\% &  84.54 \\
		PP      &   92.32\% &  95.41\% &  93.84 \\
		PRT     &  100.00\% &  33.33\% &  50.00 \\
		RB      &    0.00\% &   0.00\% &   0.00 \\
		SBAR    &   92.93\% &  60.88\% &  73.57 \\
		VBN     &    0.00\% &   0.00\% &   0.00 \\
		VP      &   92.39\% &  92.91\% &  92.65 \\
 		DQE &    0.00\% &   0.00\% &   0.00 \\\hline
		Overall &   84.95\% &  86.34\% &  85.64 \\\hline
	\end{tabular}
\end{center}


De estas métricas las que nos interesan son VP (P:92.39\% - R:92.91\%) 
y NP (P:86.60\% - R:82.57\%). 


\subsubsection{WsjSubset}

\texttt{../../conlleval.pl -l < cmp/wsjsubset.compare}

\begin{center}
	\begin{tabular}{| c | c | c | c |}
		\hline
			& Precision &  Recall  & FF-Measure \\\hline
		''      &    0.00\% &   0.00\% &   0.00 \\
		ADJP    &   79.89\% &  67.12\% &  72.95 \\
		ADVP    &   80.79\% &  77.71\% &  79.22 \\
		CC      &    0.00\% &   0.00\% &   0.00 \\
		CD      &    0.00\% &   0.00\% &   0.00 \\
		CONJP   &   57.14\% &  44.44\% &  50.00 \\
		DT      &    0.00\% &   0.00\% &   0.00 \\
		IN      &    0.00\% &   0.00\% &   0.00 \\
		INTJ    &   50.00\% &  50.00\% &  50.00 \\
		JJ      &    0.00\% &   0.00\% &   0.00 \\
		JJR     &    0.00\% &   0.00\% &   0.00 \\
		LST     &    0.00\% &   0.00\% &   0.00 \\
		MD      &    0.00\% &   0.00\% &   0.00 \\
		NN      &    0.00\% &   0.00\% &   0.00 \\
		NNP     &    0.00\% &   0.00\% &   0.00 \\
		NNPS    &    0.00\% &   0.00\% &   0.00 \\
		NP      &   88.56\% &  90.06\% &  89.30 \\
		PP      &   94.23\% &  97.69\% &  95.93 \\
		PRP     &    0.00\% &   0.00\% &   0.00 \\
		PRT     &   75.00\% &  59.43\% &  66.32 \\
		RB      &    0.00\% &   0.00\% &   0.00 \\
		RBS     &    0.00\% &   0.00\% &   0.00 \\
		SBAR    &   87.84\% &  66.17\% &  75.48 \\
		TO      &    0.00\% &   0.00\% &   0.00 \\
		VB      &    0.00\% &   0.00\% &   0.00 \\
		VBD     &    0.00\% &   0.00\% &   0.00 \\
		VBN     &    0.00\% &   0.00\% &   0.00 \\
		VBZ     &    0.00\% &   0.00\% &   0.00 \\
		VP      &   93.06\% &  92.94\% &  93.00 \\
		``      &    0.00\% &   0.00\% &   0.00 \\\hline
		Overall &   84.88\% &  90.58\% &  87.63 \\\hline
	\end{tabular}
\end{center}

De estas métricas las que nos interesan son VP (P:93.06\% - R:92.94\%) 
y NP (P:88.56\% - R:90.06\%). 

\subsection{Resultados}

Se puede observar como mejoran los resultados tanto en chunking como postagging para el wsjsubset en relación al genia, que tiene términos particulares de la biología. 

También se puede destacar como en las cinco dimensiones de error más frecuentes, se encuentran la mayoría de lo errores, siendo de gran incidencia en ambos casos. 

En el caso de Genia es destacable que la principal y mayor causa de error es NN y NNP con ambos modelos. Y en relación ambos es relevante que con maxent alrededor del 0.15 se deben a JJ y NN, mientras que con perceptron tienen una incidencia un poco menor debido a la aparición de del tag `` que se ve confundido con NN y JJ. 

Si bien no es tan alta la diferencia de la métrica de postagging accuracy entre perceptron y maxent, este último lo supera en ambos corpus. También se puede ver que las principales causas de error se mantienen y con valores similares, sobre todo en Wsjsubset, y que lo mismo sucede con el porcentaje de incidencia total. 


