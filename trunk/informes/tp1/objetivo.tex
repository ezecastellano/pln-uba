\section{Objetivo}

Tokenizar es el proceso de partir un texto en elementos denominado tokens. Llamamos tokens a unidades indivisibles. Un tokenizador es el primero de los componentes que se utiliza en el procesamiento de texto. La lista de tokens generados se usa en las siguientes etapas de esta tarea. Si bien hay muchos tokenizadores disponibles, siempre es necesario adaptarlos para objetivos o dominios espec\'ificos. 

El objetivo del trabajo es entender el funcionamiento de un tokenizador y los problemas que presenta este proceso. 